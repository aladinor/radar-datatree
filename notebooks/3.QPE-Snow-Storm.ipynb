{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "opening-hook",
   "metadata": {},
   "source": "# Computing Snow Accumulation from the December 2025 Illinois Winter Storm\n\n<img src=\"../images/illinois_winter_storm_2024.jpg\" width=700 alt=\"Snow-covered neighborhood in Illinois after a winter storm\">\n\n*Photo: A. Ladino-Rincon*\n\n---"
  },
  {
   "cell_type": "markdown",
   "id": "geographic-context",
   "metadata": {},
   "source": "## The Storm: December 13-14, 2025\n\nA powerful winter storm moved through the Midwest, bringing heavy snowfall to northern Illinois. The NEXRAD radar at **KLOT (Chicago)** captured the entire event in real-time (see [Notebook 1](1.NEXRAD-KLOT-Demo) for KLOT's geographic coverage).\n\n**Storm Timeline**:\n- **December 13, 12:00 UTC**: Snow begins spreading across northern Illinois\n- **December 13, 18:00 UTC**: Peak intensity, with heavy snowfall rates\n- **December 14, 00:00 UTC**: Snow continues, gradually tapering off\n- **December 14, 06:00 UTC**: Storm exits the region"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports-setup",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T17:01:52.838263Z",
     "iopub.status.busy": "2026-02-05T17:01:52.838102Z",
     "iopub.status.idle": "2026-02-05T17:01:53.856506Z",
     "shell.execute_reply": "2026-02-05T17:01:53.855767Z"
    }
   },
   "outputs": [],
   "source": "import sys\nimport warnings\nfrom pathlib import Path\n\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\n# Ensure demo_functions is importable (needed when executed from docs/)\nsys.path.insert(0, str(Path(\"../notebooks\").resolve()))\n\n# Geographic visualization\nimport cartopy.crs as ccrs\nimport cartopy.feature as cfeature\n\n# Radar-specific tools\nimport cmweather  # noqa: F401 - Radar colormaps\nimport icechunk as ic\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport xarray as xr\nfrom demo_functions import concat_sweep_across_vcps, rain_depth\n\nprint(f\"xarray version: {xr.__version__}\")\nprint(f\"icechunk version: {ic.__version__}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geographic-map",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T17:01:53.858186Z",
     "iopub.status.busy": "2026-02-05T17:01:53.857866Z",
     "iopub.status.idle": "2026-02-05T17:01:53.861247Z",
     "shell.execute_reply": "2026-02-05T17:01:53.860666Z"
    }
   },
   "outputs": [],
   "source": "# Radar location (for reference in later calculations)\nklot_lat = 41.6044\nklot_lon = -88.0847"
  },
  {
   "cell_type": "markdown",
   "id": "qpe-fundamentals",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## QPE Fundamentals: From Radar Reflectivity to Snow Depth\n",
    "\n",
    "### The Challenge\n",
    "\n",
    "Weather radar measures **reflectivity** (Z), which tells us how much energy bounces back from precipitation particles. But what we want to know is **how much snow fell** - that requires converting Z into precipitation rate (R), then accumulating over time.\n",
    "\n",
    "### The Z-R Relationship\n",
    "\n",
    "The fundamental equation relating reflectivity to precipitation rate is:\n",
    "\n",
    "$$Z = a \\cdot R^b$$\n",
    "\n",
    "Where:\n",
    "- **Z**: Radar reflectivity (in linear units, not dBZ)\n",
    "- **R**: Precipitation rate (mm/hr)\n",
    "- **a, b**: Empirical coefficients that depend on precipitation type\n",
    "\n",
    "Rearranging to solve for R:\n",
    "\n",
    "$$R = \\left(\\frac{Z}{a}\\right)^{1/b}$$\n",
    "\n",
    "```{important}\n",
    "**The key insight**: Different precipitation types have different Z-R relationships because particle size, shape, and density vary.\n",
    "\n",
    "- **Rain**: Dense, uniform drops with predictable size distributions\n",
    "- **Snow**: Low-density aggregates with highly variable shapes\n",
    "```\n",
    "\n",
    "### Rain vs Snow Coefficients\n",
    "\n",
    "Here are the empirical coefficients we'll use:\n",
    "\n",
    "| Precipitation Type | a | b | Reference |\n",
    "|-------------------|---|---|----------|\n",
    "| **Rain** (Marshall-Palmer) | 200 | 1.6 | Marshall & Palmer (1948) |\n",
    "| **Snow** (WSR-88D default) | 75 | 2.0 | Marshall-Gunn (1958) |\n",
    "\n",
    "```{note}\n",
    "**Why these coefficients?** The WSR-88D (NEXRAD) operational snow algorithm uses a=75, b=2.0, which is based on Marshall & Gunn (1958). This relationship is well-validated for aggregate snow in the midlatitudes and gives reasonable accumulation estimates.\n",
    "```\n",
    "\n",
    "```{tip}\n",
    "**Z-S relationships vary widely!** Values of 'a' range from 40 to 2000 in the literature. The WSR-88D default (a=75) is a good middle ground for typical winter storms. For specific storm types, different relationships may be more appropriate.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accumulation-concept",
   "metadata": {},
   "source": [
    "### From Rates to Accumulation\n",
    "\n",
    "Once we have precipitation **rate** (mm/hr), we need to integrate over **time** to get total **accumulation** (mm):\n",
    "\n",
    "$$\\text{Accumulation} = \\sum_{i=1}^{N} R_i \\cdot \\Delta t_i$$\n",
    "\n",
    "Where:\n",
    "- $R_i$: Precipitation rate at time step *i*\n",
    "- $\\Delta t_i$: Time interval between scans (typically 4-6 minutes for NEXRAD)\n",
    "\n",
    "The `rain_depth()` function in `demo_functions.py` handles this automatically by:\n",
    "1. Converting reflectivity from dBZ to linear units\n",
    "2. Applying the Z-R relationship\n",
    "3. Integrating over the `vcp_time` dimension\n",
    "\n",
    "```{note}\n",
    "**Liquid equivalent vs actual snow depth**\n",
    "\n",
    "The output is in **liquid equivalent** (mm of water if the snow melted). To convert to actual snow depth, use the snow-to-liquid ratio (SLR):\n",
    "\n",
    "$$\\text{Snow Depth (inches)} = \\text{Liquid Equivalent (inches)} \\times \\text{SLR}$$\n",
    "\n",
    "Typical SLR values:\n",
    "- Wet, heavy snow: 5:1 to 10:1\n",
    "- Average: 10:1 to 15:1\n",
    "- Dry, fluffy snow: 15:1 to 30:1\n",
    "\n",
    "We'll use **10:1** (a conservative estimate) for this storm.\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-access",
   "metadata": {},
   "source": [
    "## Accessing the Storm Data\n",
    "\n",
    "Now let's connect to the KLOT radar archive and load the December 13-14 storm data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connection-step",
   "metadata": {},
   "source": [
    "### Step 1: Connect to Icechunk Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connect-storage",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T17:01:54.111447Z",
     "iopub.status.busy": "2026-02-05T17:01:54.111301Z",
     "iopub.status.idle": "2026-02-05T17:01:54.337140Z",
     "shell.execute_reply": "2026-02-05T17:01:54.336545Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Connect to KLOT data on Open Storage Network\n",
    "storage = ic.s3_storage(\n",
    "    bucket=\"nexrad-arco\",\n",
    "    prefix=\"KLOT-RT\",\n",
    "    endpoint_url=\"https://umn1.osn.mghpcc.org\",\n",
    "    anonymous=True,\n",
    "    force_path_style=True,\n",
    "    region=\"us-east-1\",\n",
    ")\n",
    "\n",
    "# Open repository and create read-only session\n",
    "repo = ic.Repository.open(storage)\n",
    "session = repo.readonly_session(\"main\")\n",
    "\n",
    "print(\"Connected to KLOT radar archive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "open-datatree-step",
   "metadata": {},
   "source": [
    "### Step 2: Open DataTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "open-datatree",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T17:01:54.338360Z",
     "iopub.status.busy": "2026-02-05T17:01:54.338191Z",
     "iopub.status.idle": "2026-02-05T17:01:55.614711Z",
     "shell.execute_reply": "2026-02-05T17:01:55.614091Z"
    }
   },
   "outputs": [],
   "source": "%%time\n# Open DataTree (lazy loading)\ndtree = xr.open_datatree(\n    session.store,\n    zarr_format=3,\n    consolidated=False,\n    chunks={},\n    engine=\"zarr\",\n    max_concurrency=5,\n)\n\nprint(f\"DataTree opened: {dtree.nbytes / 1024**3:.1f} GB total\")\nprint(f\"Available VCPs: {sorted(dtree.children)}\")\n\n# Show xarray's beautiful Dataset representation\ndtree[\"VCP-34/sweep_0\"].ds"
  },
  {
   "cell_type": "markdown",
   "id": "multi-vcp-challenge",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Handling Multi-VCP Data: The Continuous Storm Challenge\n",
    "\n",
    "### The Problem\n",
    "\n",
    "During a storm, the radar **automatically switches** between different Volume Coverage Patterns (VCPs) based on weather conditions:\n",
    "\n",
    "```\n",
    "Timeline:\n",
    "├─ 12:00 UTC: VCP-34 (clear air mode)\n",
    "├─ 14:00 UTC: VCP-212 (precipitation mode) ← Radar detects intensifying storm\n",
    "├─ 18:00 UTC: VCP-35 (severe weather mode) ← Peak intensity\n",
    "└─ 22:00 UTC: VCP-212 (precipitation mode) ← Storm weakens\n",
    "```\n",
    "\n",
    "Each VCP has its own **hierarchical branch** in the DataTree. If we only load one VCP, we'd have **gaps** in our time series.\n",
    "\n",
    "```{warning}\n",
    "**Common mistake**: Computing accumulation from a single VCP will underestimate total snowfall because you're missing entire time periods when other VCPs were active.\n",
    "```\n",
    "\n",
    "### The Solution: Concatenate Across VCPs\n",
    "\n",
    "The `concat_sweep_across_vcps()` function (from `demo_functions.py`) solves this by:\n",
    "1. Finding all VCP nodes in the DataTree\n",
    "2. Extracting the same sweep (e.g., `sweep_0`) from each VCP\n",
    "3. Concatenating them along the `vcp_time` dimension\n",
    "4. Sorting by time to create a continuous time series\n",
    "\n",
    "```python\n",
    "# Example usage\n",
    "continuous_data = concat_sweep_across_vcps(\n",
    "    dtree,\n",
    "    sweep_name=\"sweep_0\",  # Lowest elevation angle\n",
    "    append_dim=\"vcp_time\",\n",
    "    sort_by_time=True       # Ensure chronological order\n",
    ")\n",
    "```\n",
    "\n",
    "```{tip}\n",
    "**Why sweep_0?**\n",
    "\n",
    "For QPE (precipitation accumulation), we use the **lowest elevation sweep** (sweep_0) because:\n",
    "- It's closest to the ground (where we want to measure accumulation)\n",
    "- All VCPs include sweep_0, ensuring compatibility\n",
    "- Higher sweeps sample the atmosphere aloft, not surface precipitation\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concatenate-sweeps",
   "metadata": {},
   "source": [
    "### Step 3: Create Continuous Time Series\n",
    "\n",
    "Let's concatenate `sweep_0` across all VCPs to create an uninterrupted storm record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concat-all-vcps",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T17:01:55.617296Z",
     "iopub.status.busy": "2026-02-05T17:01:55.616819Z",
     "iopub.status.idle": "2026-02-05T17:01:55.636011Z",
     "shell.execute_reply": "2026-02-05T17:01:55.635290Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Concatenate sweep_0 across all VCPs\n",
    "sweep_0_continuous = concat_sweep_across_vcps(\n",
    "    dtree,\n",
    "    sweep_name=\"sweep_0\",\n",
    "    append_dim=\"vcp_time\",\n",
    "    validate_coords=True,  # Verify spatial compatibility\n",
    "    sort_by_time=True,  # Chronological order\n",
    ")\n",
    "\n",
    "print(\"Continuous dataset created\")\n",
    "print(\n",
    "    f\"Time span: {sweep_0_continuous.vcp_time.min().values} to {sweep_0_continuous.vcp_time.max().values}\"\n",
    ")\n",
    "print(f\"Number of scans: {len(sweep_0_continuous.vcp_time)}\")\n",
    "print(f\"Variables: {list(sweep_0_continuous.data_vars)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "time-selection",
   "metadata": {},
   "source": [
    "### Step 4: Select Storm Time Window\n",
    "\n",
    "Now we can directly slice the time period of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "select-storm-window",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T17:01:55.637949Z",
     "iopub.status.busy": "2026-02-05T17:01:55.637698Z",
     "iopub.status.idle": "2026-02-05T17:01:55.648605Z",
     "shell.execute_reply": "2026-02-05T17:01:55.647982Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define storm period (December 13, 12:00 UTC to December 14, 06:00 UTC)\n",
    "STORM_START = \"2025-12-13T12:00\"\n",
    "STORM_END = \"2025-12-14T06:00\"\n",
    "\n",
    "# Select storm window\n",
    "storm_data = sweep_0_continuous.sel(vcp_time=slice(STORM_START, STORM_END))\n",
    "\n",
    "num_scans = len(storm_data.vcp_time)\n",
    "duration_hours = (\n",
    "    (storm_data.vcp_time[-1] - storm_data.vcp_time[0])\n",
    "    .values.astype(\"timedelta64[h]\")\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "print(\"Storm window selected:\")\n",
    "print(f\"  Start: {storm_data.vcp_time.min().values}\")\n",
    "print(f\"  End: {storm_data.vcp_time.max().values}\")\n",
    "print(f\"  Duration: {duration_hours} hours\")\n",
    "print(f\"  Number of scans: {num_scans}\")\n",
    "print(f\"  Average scan interval: {duration_hours * 60 / num_scans:.1f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflectivity-overview",
   "metadata": {},
   "source": [
    "### Visualizing Storm Evolution\n",
    "\n",
    "Before computing accumulation, let's see how reflectivity evolved during the storm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "storm-evolution-plot",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T17:01:55.649931Z",
     "iopub.status.busy": "2026-02-05T17:01:55.649796Z",
     "iopub.status.idle": "2026-02-05T17:02:04.617516Z",
     "shell.execute_reply": "2026-02-05T17:02:04.617070Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sample 6 evenly-spaced time points throughout the storm\n",
    "sample_indices = np.linspace(0, len(storm_data.vcp_time) - 1, 6, dtype=int)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, time_idx in enumerate(sample_indices):\n",
    "    scan = storm_data.isel(vcp_time=time_idx)\n",
    "    time_str = str(scan.vcp_time.values)[:16].replace(\"T\", \" \")\n",
    "\n",
    "    scan.DBZH.plot(\n",
    "        ax=axes[idx],\n",
    "        x=\"x\",\n",
    "        y=\"y\",\n",
    "        cmap=\"ChaseSpectral\",\n",
    "        vmin=-10,\n",
    "        vmax=50,\n",
    "        add_colorbar=True,\n",
    "        cbar_kwargs={\"label\": \"dBZ\", \"shrink\": 0.8},\n",
    "    )\n",
    "    axes[idx].set_title(f\"{time_str} UTC\", fontsize=10, fontweight=\"bold\")\n",
    "    axes[idx].set_xlabel(\"East (m)\", fontsize=9)\n",
    "    axes[idx].set_ylabel(\"North (m)\", fontsize=9)\n",
    "    axes[idx].set_aspect(\"equal\")\n",
    "\n",
    "fig.suptitle(\n",
    "    \"December 2025 Winter Storm - Reflectivity Evolution\",\n",
    "    fontsize=12,\n",
    "    fontweight=\"bold\",\n",
    "    y=0.995,\n",
    ")\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.99])\n",
    "plt.show()\n",
    "\n",
    "print(f\"✓ Displayed storm evolution across {len(sample_indices)} time steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qpe-computation",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Computing Snow Accumulation\n",
    "\n",
    "Now comes the main event: converting reflectivity into snowfall accumulation.\n",
    "\n",
    "### The Process\n",
    "\n",
    "We'll use the `rain_depth()` function with **WSR-88D snow coefficients**:\n",
    "- **a = 75** (Marshall-Gunn)\n",
    "- **b = 2.0**\n",
    "\n",
    "The function will:\n",
    "1. Convert DBZH from dBZ to linear units\n",
    "2. Apply the Z-S relationship: $R = (Z/75)^{1/2.0}$\n",
    "3. Integrate precipitation rates over the `vcp_time` dimension\n",
    "4. Return total liquid equivalent accumulation (mm)\n",
    "\n",
    "```{note}\n",
    "This computation happens **lazily** - the data only streams when we call `.compute()`.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compute-qpe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T17:02:04.619746Z",
     "iopub.status.busy": "2026-02-05T17:02:04.619602Z",
     "iopub.status.idle": "2026-02-05T17:02:05.997441Z",
     "shell.execute_reply": "2026-02-05T17:02:05.996864Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Compute snow accumulation (liquid equivalent)\n",
    "# Using WSR-88D snow coefficients (Marshall-Gunn 1958)\n",
    "snow_depth_per_scan = rain_depth(\n",
    "    storm_data.DBZH,\n",
    "    a=75,  # WSR-88D snow coefficient\n",
    "    b=2.0,  # WSR-88D snow coefficient\n",
    "    t=None,  # Auto-compute from vcp_time dimension\n",
    ")\n",
    "\n",
    "# Sum over time to get total accumulation and load into memory\n",
    "snow_accumulation = snow_depth_per_scan.sum(dim=\"vcp_time\", skipna=True).compute()\n",
    "\n",
    "print(\"\\nSnow accumulation computed successfully\")\n",
    "print(f\"Result shape: {snow_accumulation.shape}\")\n",
    "print(f\"Dimensions: {snow_accumulation.dims}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-visualization",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Geographic Visualization: Where Did the Snow Fall?\n",
    "\n",
    "Now let's create a map showing snow accumulation across northern Illinois."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accumulation-map",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T17:02:06.013130Z",
     "iopub.status.busy": "2026-02-05T17:02:06.012967Z",
     "iopub.status.idle": "2026-02-05T17:02:13.477897Z",
     "shell.execute_reply": "2026-02-05T17:02:13.477406Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert accumulation to inches for U.S. audience\n",
    "snow_accumulation_inches = snow_accumulation * (1 / 25.4)\n",
    "\n",
    "# Estimate snow depth (using 10:1 SLR)\n",
    "snow_depth_inches = snow_accumulation_inches * 10\n",
    "\n",
    "# KLOT radar location\n",
    "klot_lat = 41.6044\n",
    "klot_lon = -88.0847\n",
    "\n",
    "# Create geographic map with cartopy\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = plt.axes(\n",
    "    projection=ccrs.LambertConformal(\n",
    "        central_longitude=klot_lon, central_latitude=klot_lat\n",
    "    )\n",
    ")\n",
    "\n",
    "# Set extent to cover radar domain (~250 km around radar)\n",
    "ax.set_extent(\n",
    "    [klot_lon - 3.5, klot_lon + 3.5, klot_lat - 2.5, klot_lat + 2.5],\n",
    "    crs=ccrs.PlateCarree(),\n",
    ")\n",
    "\n",
    "# Add geographic features\n",
    "ax.add_feature(cfeature.STATES, linewidth=1.5, edgecolor=\"black\", zorder=3)\n",
    "ax.add_feature(cfeature.COASTLINE, linewidth=1, zorder=3)\n",
    "ax.add_feature(cfeature.LAKES, alpha=0.5, facecolor=\"lightblue\", zorder=2)\n",
    "\n",
    "# Plot snow accumulation using x/y coordinates (meters from radar)\n",
    "# Transform x/y from radar-centered meters to lat/lon for plotting\n",
    "if \"x\" in snow_depth_inches.coords and \"y\" in snow_depth_inches.coords:\n",
    "    # Get x, y coordinates (in meters from radar)\n",
    "    x_vals = snow_depth_inches.x.values  # 2D array\n",
    "    y_vals = snow_depth_inches.y.values  # 2D array\n",
    "\n",
    "    # Convert to approximate lat/lon (simple offset from radar location)\n",
    "    # Note: This is approximate; for exact georeferencing use pyproj\n",
    "    lon_vals = klot_lon + (x_vals / 111000) / np.cos(np.radians(klot_lat))\n",
    "    lat_vals = klot_lat + (y_vals / 111000)\n",
    "\n",
    "    # Plot with pcolormesh for geographic overlay\n",
    "    p2, p98 = np.nanpercentile(snow_depth_inches.values, [2, 98])\n",
    "    im = ax.pcolormesh(\n",
    "        lon_vals,\n",
    "        lat_vals,\n",
    "        snow_depth_inches.values,\n",
    "        cmap=\"Blues\",\n",
    "        vmin=0,\n",
    "        vmax=max(p98, 1),\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        zorder=1,\n",
    "        alpha=0.8,\n",
    "    )\n",
    "    plt.colorbar(im, ax=ax, label=\"Est. Snow Depth (in)\", shrink=0.7, pad=0.02)\n",
    "\n",
    "# Mark radar location\n",
    "ax.plot(\n",
    "    klot_lon,\n",
    "    klot_lat,\n",
    "    marker=\"*\",\n",
    "    markersize=20,\n",
    "    color=\"red\",\n",
    "    markeredgecolor=\"black\",\n",
    "    markeredgewidth=1.5,\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    label=\"KLOT Radar\",\n",
    "    zorder=10,\n",
    ")\n",
    "\n",
    "# Add city markers\n",
    "cities = {\n",
    "    \"Chicago\": (41.8781, -87.6298),\n",
    "    \"Rockford\": (42.2711, -89.0940),\n",
    "    \"Joliet\": (41.5250, -88.0817),\n",
    "}\n",
    "for city, (lat, lon) in cities.items():\n",
    "    ax.plot(\n",
    "        lon,\n",
    "        lat,\n",
    "        marker=\"o\",\n",
    "        markersize=6,\n",
    "        color=\"black\",\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        zorder=9,\n",
    "    )\n",
    "    ax.text(\n",
    "        lon + 0.12,\n",
    "        lat,\n",
    "        city,\n",
    "        fontsize=9,\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        ha=\"left\",\n",
    "        fontweight=\"bold\",\n",
    "        bbox=dict(facecolor=\"white\", alpha=0.7, edgecolor=\"none\", pad=1),\n",
    "    )\n",
    "\n",
    "ax.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=False, alpha=0.3)\n",
    "ax.legend(loc=\"upper right\", fontsize=10)\n",
    "ax.set_title(\n",
    "    \"December 13-14, 2025 Snow Accumulation\\nNEXRAD KLOT (10:1 SLR)\",\n",
    "    fontsize=12,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    \"snow_accumulation_map.png\", dpi=150, bbox_inches=\"tight\", facecolor=\"white\"\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✓ Figure saved. Color scale: 0 to {max(p98, 1):.1f} inches (98th percentile)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-section",
   "metadata": {},
   "source": [
    "### Cross-Sections: Accumulation Profiles\n",
    "\n",
    "Let's examine accumulation along transects through the domain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-cross-sections",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T17:02:13.482080Z",
     "iopub.status.busy": "2026-02-05T17:02:13.481934Z",
     "iopub.status.idle": "2026-02-05T17:02:13.706835Z",
     "shell.execute_reply": "2026-02-05T17:02:13.706310Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Radial profile (average across all azimuths)\n",
    "range_km = snow_depth_inches.range.values / 1000\n",
    "radial_profile = snow_depth_inches.mean(dim=\"azimuth\", skipna=True)\n",
    "\n",
    "ax1.plot(range_km, radial_profile.values, \"b-\", linewidth=2)\n",
    "ax1.axvline(0, color=\"red\", linestyle=\"--\", linewidth=1.5, label=\"Radar\", alpha=0.7)\n",
    "ax1.set_xlabel(\"Distance from Radar (km)\", fontsize=10)\n",
    "ax1.set_ylabel(\"Est. Snow Depth (in)\", fontsize=10)\n",
    "ax1.set_title(\"Radial Profile (Azimuth Average)\", fontsize=11, fontweight=\"bold\")\n",
    "ax1.legend(fontsize=9)\n",
    "ax1.grid(alpha=0.3)\n",
    "ax1.set_xlim(0, 230)\n",
    "# Auto-scale y-axis based on data\n",
    "ax1.set_ylim(0, max(radial_profile.max().values * 1.1, 0.5))\n",
    "\n",
    "# Azimuthal profile at 100 km range\n",
    "target_range_m = 100000\n",
    "az_profile = snow_depth_inches.sel(range=target_range_m, method=\"nearest\")\n",
    "\n",
    "ax2.plot(az_profile.azimuth.values, az_profile.values, \"g-\", linewidth=2)\n",
    "ax2.set_xlabel(\"Azimuth (degrees)\", fontsize=10)\n",
    "ax2.set_ylabel(\"Est. Snow Depth (in)\", fontsize=10)\n",
    "ax2.set_title(\"Azimuthal Profile at 100 km\", fontsize=11, fontweight=\"bold\")\n",
    "ax2.grid(alpha=0.3)\n",
    "ax2.set_xlim(0, 360)\n",
    "# Auto-scale y-axis\n",
    "ax2.set_ylim(0, max(float(az_profile.max(skipna=True).values) * 1.1, 0.5))\n",
    "for az, label in [(0, \"N\"), (90, \"E\"), (180, \"S\"), (270, \"W\")]:\n",
    "    ax2.axvline(az, color=\"gray\", linestyle=\":\", alpha=0.5)\n",
    "    ax2.text(az, ax2.get_ylim()[1] * 0.9, label, ha=\"center\", fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Max radial accumulation: {radial_profile.max().values:.2f} inches\")\n",
    "print(\n",
    "    f\"Max azimuthal accumulation at 100 km: {az_profile.max(skipna=True).values:.2f} inches\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uncertainty-discussion",
   "metadata": {},
   "source": "---\n\n## Scientific Integrity: Understanding Your Results\n\nEvery radar-derived estimate has inherent uncertainty. Knowing these limits is what separates credible analysis from naive code execution.\n\n### Key Sources of Uncertainty\n\n| Source | Impact | Notes |\n|--------|--------|-------|\n| **Z-R coefficients** | ±30–70% | Snowflake density, size, and crystal habit vary with temperature and humidity |\n| **Beam height** | Increases with range | At far ranges the beam samples well above the surface; estimates most reliable within ~100 km |\n| **Bright band** | Overestimation | Melting snow produces artificially high reflectivity; QVPs help identify this |\n| **Ground clutter / blockage** | Localized errors | Buildings, terrain can block or reflect the beam |\n| **SLR assumption** | ±50%+ | We used 10:1, but real SLR ranges from 5:1 (wet snow) to 30:1+ (dry, fluffy snow) |\n\n```{tip}\n**For publications**, include a statement like: *\"Radar-derived QPE estimates have typical uncertainties of ±30–50% for snow events (Roebber et al., 2003). Validation against surface observations is recommended.\"*\n```\n\n---"
  },
  {
   "cell_type": "markdown",
   "id": "validation",
   "metadata": {},
   "source": [
    "### Validation Strategy (Future Work)\n",
    "\n",
    "To improve confidence in radar QPE:\n",
    "\n",
    "1. **Ground truth comparison**:\n",
    "   - CoCoRaHS volunteer observations\n",
    "   - Automated ASOS/AWOS stations\n",
    "   - Snowboard measurements\n",
    "\n",
    "2. **Multi-sensor fusion**:\n",
    "   - Combine radar with satellite (MRMS products)\n",
    "   - Gauge correction factors\n",
    "   - Model QPF for storm structure\n",
    "\n",
    "3. **Improved Z-S relationships**:\n",
    "   - Use polarimetric variables (ZDR, KDP) to classify snow type\n",
    "   - Apply different coefficients for different hydrometeor classes\n",
    "   - Adjust for temperature profiles\n",
    "\n",
    "```{tip}\n",
    "**Research opportunity**: Compare your radar estimates with official snowfall reports. Where do they agree? Disagree? Why might that be?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary: What You've Accomplished\n",
    "\n",
    "**You just computed snowfall accumulation for an entire winter storm — from your laptop!**\n",
    "\n",
    "This is publication-quality analysis. Seriously. You now have the skills to analyze any winter storm in the 30+ year NEXRAD archive.\n",
    "\n",
    "### Skills You've Mastered\n",
    "\n",
    "1. **QPE fundamentals**:\n",
    "   - Z-R relationships for rain vs snow\n",
    "   - Time integration to compute accumulation\n",
    "   - Liquid equivalent vs actual snow depth\n",
    "\n",
    "2. **Multi-VCP data handling**:\n",
    "   - Used `concat_sweep_across_vcps()` for continuous time series\n",
    "   - Understood why radar switches VCPs during storms\n",
    "\n",
    "3. **Cloud-native workflows**:\n",
    "   - Connected to KLOT archive on OSN\n",
    "   - Streamed only the data needed (sweep_0, storm window)\n",
    "   - Computed accumulation without downloading files\n",
    "\n",
    "4. **Scientific visualization**:\n",
    "   - Geographic accumulation maps\n",
    "   - Storm evolution time series\n",
    "   - Radial and azimuthal profiles\n",
    "\n",
    "5. **Scientific integrity**:\n",
    "   - Z-R relationship variability\n",
    "   - Beam height effects\n",
    "   - Uncertainty quantification and communication\n",
    "\n",
    "### The Big Picture\n",
    "\n",
    "This workflow would have been:\n",
    "- **Impossible** 10 years ago (data not archived at this resolution)\n",
    "- **Tedious** 5 years ago (download hundreds of files, decode each one)\n",
    "- **Trivial** today (stream on-demand, compute in memory)\n",
    "\n",
    "**This is the power of FAIR, cloud-native data.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next-steps",
   "metadata": {},
   "source": [
    "## Next Steps: Extend Your Analysis\n",
    "\n",
    "```{admonition} Challenge Yourself\n",
    ":class: tip\n",
    "\n",
    "Ready to go deeper? Try these extensions:\n",
    "\n",
    "1. **Compare with ground truth**: Download snowfall reports from CoCoRaHS and compare with radar estimates\n",
    "\n",
    "2. **Improve the Z-S relationship**: Use ZDR and KDP for hydrometeor classification\n",
    "\n",
    "3. **Analyze storm structure**: Compute QVPs to see vertical structure\n",
    "\n",
    "4. **Scale to other storms**: Analyze the entire winter season (December-February)\n",
    "```\n",
    "\n",
    "### Related Notebooks\n",
    "\n",
    "Continue your learning:\n",
    "\n",
    "- **[1. Getting Started with Radar DataTree](1.NEXRAD-KLOT-Demo)**: Basics of data access and visualization\n",
    "- **[2. QVP Workflow Comparison](2.QVP-Workflow-Comparison)**: Cloud-native vs traditional workflows\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "references",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "### Z-R Relationships\n",
    "\n",
    "- **Marshall, J. S., & Palmer, W. M.** (1948). The distribution of raindrops with size. *Journal of Meteorology*, 5(4), 165-166.\n",
    "\n",
    "- **Marshall, J. S., & Gunn, K. L. S.** (1958). Measurement of snow parameters by radar. *Journal of Meteorology*, 15(2), 209-215. *(Used for WSR-88D snow algorithm)*\n",
    "\n",
    "### Radar QPE Techniques\n",
    "\n",
    "- **Cifelli, R., Chandrasekar, V., Lim, S., Kennedy, P. C., Wang, Y., & Rutledge, S. A.** (2011). A new dual-polarization radar rainfall algorithm: Application in Colorado precipitation events. *Journal of Atmospheric and Oceanic Technology*, 28(3), 352-364.\n",
    "\n",
    "- **Gourley, J. J., et al.** (2017). The FLASH Project: Improving the Tools for Flash Flood Monitoring and Prediction across the United States. *Bulletin of the American Meteorological Society*, 98(2), 361-372.\n",
    "\n",
    "### Snow-to-Liquid Ratios\n",
    "\n",
    "- **Roebber, P. J., Bruening, S. L., Schultz, D. M., & Cortinas Jr, J. V.** (2003). Improving snowfall forecasting by diagnosing snow density. *Weather and Forecasting*, 18(2), 264-287.\n",
    "\n",
    "### Radar DataTree Framework\n",
    "\n",
    "- **Ladino-Rincón, A., & Nesbitt, S. W.** (2025). Radar DataTree: A FAIR and Cloud-Native Framework for Scalable Weather Radar Archives. *arXiv preprint arXiv:2510.24943*. https://doi.org/10.48550/arXiv.2510.24943\n",
    "\n",
    "---\n",
    "\n",
    "## Citation\n",
    "\n",
    "If you use this notebook or framework in your research, please cite:\n",
    "\n",
    "> Ladino-Rincón, A., & Nesbitt, S. W. (2025). *Radar DataTree: A FAIR and Cloud-Native Framework for Scalable Weather Radar Archives.* arXiv:2510.24943. [doi:10.48550/arXiv.2510.24943](https://doi.org/10.48550/arXiv.2510.24943)\n",
    "\n",
    "---\n",
    "\n",
    "*Tutorial created by the Radar DataTree team*\n",
    "\n",
    "*Last updated: February 2025*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
