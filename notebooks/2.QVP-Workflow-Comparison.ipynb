{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "opening-hook",
   "metadata": {},
   "source": [
    "# Scientific Showcase: Reproducing Published Radar Science in 60 Seconds\n",
    "\n",
    "**What if you could reproduce a published scientific figure in under a minute?**\n",
    "\n",
    "Below is Figure 4 from [Ryzhkov et al. (2016)](https://doi.org/10.1175/JTECH-D-15-0020.1), showing Quasi-Vertical Profiles (QVPs) of polarimetric radar variables during a mesoscale convective system. This visualization required processing 4 hours of weather radar data from the May 20, 2011 MC3E field campaign.\n",
    "\n",
    "<img src=\"../images/full-jtech-d-15-0020_1-f4.jpg\" width=700 alt=\"QVP plot from Ryzhkov et al. 2016\">\n",
    "\n",
    "*Courtesy: Ryzhkov et al. (2016)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-comparison",
   "metadata": {},
   "source": [
    "```{important}\n",
    "**Traditionally**: Reproducing this figure takes ~6 minutes (380 seconds) of processing time:\n",
    "- Download 809 MB of compressed NEXRAD files\n",
    "- Decode 55 files from binary format\n",
    "- Load all 17 elevation sweeps (even though we only need 1)\n",
    "- Concatenate and process\n",
    "\n",
    "**With Analysis-Ready Cloud-Optimized (ARCO) data**: ~10 seconds\n",
    "- Stream only the chunks you need\n",
    "- No downloads, no file decoding\n",
    "- **36x faster**, 5.5x less data transfer\n",
    "```\n",
    "\n",
    "In this notebook, you'll learn how the Radar DataTree framework enables this dramatic speedup—and reproduce this exact scientific figure yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisites-note",
   "metadata": {},
   "source": [
    "```{note}\n",
    "**Prerequisites**\n",
    "\n",
    "This notebook assumes you're familiar with the basics covered in **[1. Getting Started with Radar DataTree](1.NEXRAD-KLOT-Demo)**:\n",
    "- Connecting to cloud storage with Icechunk\n",
    "- Opening a DataTree and navigating the VCP/sweep hierarchy\n",
    "- Time-based selection with `.sel()`\n",
    "\n",
    "If you're new to Radar DataTree, start there first.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qvp-concept-explanation",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## What is a Quasi-Vertical Profile (QVP)?\n",
    "\n",
    "Before diving into the workflow comparison, let's understand what we're computing.\n",
    "\n",
    "### The Concept: A Merry-Go-Round Analogy\n",
    "\n",
    "Imagine standing in the center of a merry-go-round during a rainstorm. As you spin, you hold out your hand at different heights to measure how much rain hits it at each level. By averaging all the measurements from your complete rotation, you get a sense of the \"typical\" rainfall at that height, smoothing out any variations from specific directions.\n",
    "\n",
    "**That's essentially what QVP does with radar data.**\n",
    "\n",
    "### How It Works\n",
    "\n",
    "At high elevation angles (e.g., 19.5°), the radar beam rises quickly with range:\n",
    "\n",
    "```\n",
    "         ↗ Beam at 19.5° elevation (sweep_16)\n",
    "        /  Height increases rapidly with range\n",
    "       /   (~3 km height at 10 km range)\n",
    "      /\n",
    "    [RADAR]\n",
    "```\n",
    "\n",
    "By **averaging all azimuth angles** (360° rotation) at each range gate, we collapse horizontal variability and create a vertical profile:\n",
    "\n",
    "$$\\text{QVP}(r, t) = \\frac{1}{N_{\\theta}} \\sum_{\\theta=0}^{360°} Z(r, \\theta, t)$$\n",
    "\n",
    "where:\n",
    "- $r$ is range (converted to height using elevation angle)\n",
    "- $\\theta$ is azimuth angle\n",
    "- $t$ is time\n",
    "- $Z$ is any radar variable (reflectivity, differential reflectivity, etc.)\n",
    "\n",
    "### Why QVPs Matter\n",
    "\n",
    "QVPs reveal critical atmospheric processes:\n",
    "- **Melting layer detection**: Where snow turns to rain\n",
    "- **Precipitation structure**: Ice crystal growth zones, aggregation layers\n",
    "- **Storm evolution**: Time-height displays show how precipitation processes change\n",
    "\n",
    "The figure we'll reproduce shows 4 hours of QVPs during a mesoscale convective system—revealing the vertical structure and temporal evolution of the storm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "study-parameters",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Study Parameters\n",
    "\n",
    "To reproduce Ryzhkov et al. (2016) Figure 4, we'll process:\n",
    "\n",
    "- **Radar**: KVNX (Vance Air Force Base, Oklahoma)\n",
    "- **Event**: MC3E field campaign mesoscale convective system\n",
    "- **Date**: May 20, 2011\n",
    "- **Time Window**: 08:30 - 12:30 UTC (4 hours)\n",
    "- **Elevation**: 19.5° (highest WSR-88D elevation, sweep_16)\n",
    "- **Variables**: DBZH (reflectivity), ZDR (differential reflectivity), RHOHV (correlation coefficient), PHIDP (differential phase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-summary",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Traditional Workflow: The Challenge\n",
    "\n",
    "The conventional approach to accessing this 4-hour window of radar data requires:\n",
    "\n",
    "1. **Discover** 55 files in the time range from AWS S3\n",
    "2. **Download** ~809 MB of compressed NEXRAD Level II files\n",
    "3. **Decode** each file from binary format (loading all 17 sweeps, all variables)\n",
    "4. **Extract** only the highest elevation sweep we need\n",
    "5. **Concatenate** along time dimension\n",
    "6. **Compute** QVPs\n",
    "\n",
    "### Benchmark Results\n",
    "\n",
    "(From full execution on standard laptop)\n",
    "\n",
    "| Step | Time |\n",
    "|------|------|\n",
    "| File discovery | ~1s |\n",
    "| Download + decode 55 files | ~375s |\n",
    "| Concatenation | ~2s |\n",
    "| QVP computation | ~2s |\n",
    "| **Total** | **~380s (6.3 min)** |\n",
    "\n",
    "**Peak RAM usage**: ~3.3 GB (loading all sweeps just to use one)\n",
    "\n",
    "```{tip}\n",
    "See `QVP-Workflow-Benchmark.ipynb` in this directory for the full traditional workflow implementation and timing details.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arco-workflow-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ARCO Workflow: Data Streaming with Radar DataTree\n",
    "\n",
    "The cloud-native approach eliminates the download-decode-process pipeline:\n",
    "\n",
    "1. **Connect**: Open Icechunk repository (metadata only, <1 second)\n",
    "2. **Navigate**: Browse the hierarchical VCP/sweep structure\n",
    "3. **Select**: Slice by time dimension (lazy, no data transfer yet)\n",
    "4. **Stream**: Data chunks fetched on-demand during computation\n",
    "\n",
    "```{important}\n",
    "**Key advantage**: No file downloads, no decoding—data streams directly from cloud storage. You only transfer the exact chunks you need.\n",
    "```\n",
    "\n",
    "Let's reproduce the Ryzhkov figure and measure performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T17:10:22.074359Z",
     "iopub.status.busy": "2026-02-05T17:10:22.074181Z",
     "iopub.status.idle": "2026-02-05T17:10:23.173773Z",
     "shell.execute_reply": "2026-02-05T17:10:23.173309Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import cmweather  # noqa: F401\n",
    "import icechunk as ic\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "from demo_functions import compute_qvp, get_repo_config, ryzhkov_figure\n",
    "\n",
    "# Study parameters\n",
    "RADAR = \"KVNX\"\n",
    "START_TIME = \"2011-05-20 08:30\"\n",
    "END_TIME = \"2011-05-20 12:30\"\n",
    "VARIABLES = [\"DBZH\", \"ZDR\", \"RHOHV\", \"PHIDP\"]\n",
    "\n",
    "print(f\"xarray: {xr.__version__}\")\n",
    "print(f\"icechunk: {ic.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arco-step1",
   "metadata": {},
   "source": [
    "### Step 1: Connect to Icechunk Repository\n",
    "\n",
    "We'll connect to the KVNX radar data on the Open Storage Network (OSN). This is metadata-only—no actual radar data is transferred yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connect-icechunk",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T17:10:23.175937Z",
     "iopub.status.busy": "2026-02-05T17:10:23.175522Z",
     "iopub.status.idle": "2026-02-05T17:10:23.789889Z",
     "shell.execute_reply": "2026-02-05T17:10:23.789324Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Configure S3-compatible storage (Open Storage Network)\n",
    "storage = ic.s3_storage(\n",
    "    bucket=\"nexrad-arco\",\n",
    "    prefix=\"KVNX\",\n",
    "    endpoint_url=\"https://umn1.osn.mghpcc.org\",\n",
    "    anonymous=True,\n",
    "    force_path_style=True,\n",
    "    region=\"us-east-1\",\n",
    ")\n",
    "\n",
    "repo = ic.Repository.open(storage, config=get_repo_config())\n",
    "session = repo.readonly_session(\"main\")\n",
    "print(\"Connected to Icechunk repository\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arco-step2",
   "metadata": {},
   "source": [
    "### Step 2: Open DataTree\n",
    "\n",
    "Opening the DataTree is a lazy operation—it reads metadata about the structure but doesn't load any actual data arrays yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "open-datatree",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T17:10:23.791496Z",
     "iopub.status.busy": "2026-02-05T17:10:23.791347Z",
     "iopub.status.idle": "2026-02-05T17:10:27.871878Z",
     "shell.execute_reply": "2026-02-05T17:10:27.871259Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Open DataTree (lazy - no data loaded yet, only metadata)\n",
    "dtree = xr.open_datatree(\n",
    "    session.store,\n",
    "    engine=\"zarr\",\n",
    "    zarr_format=3,\n",
    "    consolidated=False,\n",
    "    chunks={},\n",
    ")\n",
    "print(\"DataTree opened (lazy)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arco-step3",
   "metadata": {},
   "source": [
    "### Step 3: Navigate Hierarchy and Select Sweep\n",
    "\n",
    "The Radar DataTree organizes data hierarchically by Volume Coverage Pattern (VCP) and sweep. We'll navigate to the highest elevation sweep (sweep_16 at 19.5°), which is optimal for QVP computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "navigate-hierarchy",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T17:10:27.873388Z",
     "iopub.status.busy": "2026-02-05T17:10:27.873067Z",
     "iopub.status.idle": "2026-02-05T17:10:27.893609Z",
     "shell.execute_reply": "2026-02-05T17:10:27.893022Z"
    }
   },
   "outputs": [],
   "source": [
    "# Explore available VCPs\n",
    "print(\"Available VCPs:\", list(dtree.children))\n",
    "\n",
    "# Get highest elevation sweep\n",
    "available_sweeps = sorted(\n",
    "    [s for s in dtree[\"VCP-12\"].children if s.startswith(\"sweep_\")],\n",
    "    key=lambda x: int(x.split(\"_\")[1]),\n",
    ")\n",
    "highest_sweep = available_sweeps[-1]\n",
    "print(f\"Using {highest_sweep} for QVP computation\")\n",
    "\n",
    "# Access the sweep Dataset - xarray's beautiful representation\n",
    "ds_qvp = dtree[f\"/VCP-12/{highest_sweep}\"].ds\n",
    "ds_qvp  # Display xarray's rich HTML representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arco-step4",
   "metadata": {},
   "source": [
    "### Step 4: Select Time Range and Compute QVPs\n",
    "\n",
    "Unlike the traditional workflow, we can directly slice by time without iterating through files. Data is fetched on-demand during computation.\n",
    "\n",
    "```{tip}\n",
    "The `.sel()` operation is still lazy—no data transfer happens until we call `.compute()`. This allows you to build complex analysis pipelines before triggering any network operations.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "time-selection",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T17:10:27.895456Z",
     "iopub.status.busy": "2026-02-05T17:10:27.895314Z",
     "iopub.status.idle": "2026-02-05T17:10:27.905980Z",
     "shell.execute_reply": "2026-02-05T17:10:27.905568Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select 4-hour window (still lazy - no data fetched)\n",
    "ds_qvp_selected = ds_qvp.sel(\n",
    "    vcp_time=slice(START_TIME.replace(\" \", \"T\"), END_TIME.replace(\" \", \"T\"))\n",
    ")\n",
    "print(f\"Selected {len(ds_qvp_selected.vcp_time)} timesteps\")\n",
    "print(\n",
    "    f\"Time range: {str(ds_qvp_selected.vcp_time.min().values)[:19]} to {str(ds_qvp_selected.vcp_time.max().values)[:19]} UTC\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compute-qvp-arco",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T17:10:27.907612Z",
     "iopub.status.busy": "2026-02-05T17:10:27.907475Z",
     "iopub.status.idle": "2026-02-05T17:10:30.708805Z",
     "shell.execute_reply": "2026-02-05T17:10:30.708167Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Compute QVPs (data streams on-demand during this step)\n",
    "qvp_data = {}\n",
    "for var in VARIABLES:\n",
    "    if var in ds_qvp_selected.data_vars:\n",
    "        qvp_data[var] = compute_qvp(ds_qvp_selected, var=var).compute()\n",
    "        print(f\"  Computed QVP for {var}\")\n",
    "\n",
    "print(f\"\\nQVPs computed for {len(qvp_data)} variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reproduce-figure-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Reproducing Ryzhkov et al. (2016) Figure 4\n",
    "\n",
    "Now let's visualize the QVPs as time-height cross-sections. This 4-panel figure shows the vertical structure and temporal evolution of the storm's polarimetric signatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ryzhkov-figure",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T17:10:30.710169Z",
     "iopub.status.busy": "2026-02-05T17:10:30.710018Z",
     "iopub.status.idle": "2026-02-05T17:10:32.797214Z",
     "shell.execute_reply": "2026-02-05T17:10:32.796646Z"
    }
   },
   "outputs": [],
   "source": [
    "ryzhkov_figure(qvp_data[\"DBZH\"], qvp_data[\"ZDR\"], qvp_data[\"RHOHV\"], qvp_data[\"PHIDP\"])\n",
    "plt.savefig(\"ryzhkov_qvp_reproduction.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scientific-interpretation",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Scientific Interpretation: Reading the QVPs\n",
    "\n",
    "Congratulations! You just reproduced a published scientific figure. But what does it reveal? Let's decode each panel for non-experts.\n",
    "\n",
    "### Upper Left: Z (Reflectivity)\n",
    "\n",
    "**What it shows**: Radar energy bouncing off precipitation particles.\n",
    "\n",
    "**Key features to notice**:\n",
    "- **Bright band at ~3-4 km height**: This bright layer (yellow/orange) is the **melting layer**—where snowflakes melt into raindrops. Snowflakes are larger targets than raindrops, but when they start melting, they become coated with water, creating extremely strong radar returns.\n",
    "- **Stronger echoes aloft (~5-8 km)**: Ice crystals and snow aggregates\n",
    "- **Temporal evolution**: The storm intensifies around 10:00 UTC and persists through 12:00 UTC\n",
    "\n",
    "### Upper Right: Z_DR (Differential Reflectivity)\n",
    "\n",
    "**What it shows**: The difference in radar returns from horizontally vs. vertically polarized pulses. Tells us about particle shape.\n",
    "\n",
    "**Key features to notice**:\n",
    "- **High values above the melting layer (~4-6 km)**: Large, horizontally oriented snowflakes (aggregates). As snowflakes stick together, they become flattened and horizontally oriented, producing high Z_DR.\n",
    "- **Near-zero values below ~3 km**: Raindrops are relatively spherical at light rain rates\n",
    "- **The Z_DR column**: Enhanced values extending from mid-levels to upper levels indicate strong updrafts carrying water droplets aloft, where they freeze and form large ice particles\n",
    "\n",
    "### Lower Left: ρ_HV (Correlation Coefficient)\n",
    "\n",
    "**What it shows**: How similar horizontally and vertically polarized returns are. High values (>0.95) indicate uniform particle types.\n",
    "\n",
    "**Key features to notice**:\n",
    "- **Dip at the melting layer (~3-4 km)**: When ice melts to water, you get a mix of snow, melting particles, and raindrops—all different shapes and sizes. This chaos reduces correlation.\n",
    "- **High values above and below**: Pure ice aloft, pure rain below—uniform particle types produce high correlation\n",
    "- **Slightly lower values in intense precipitation**: Mixture of drop sizes\n",
    "\n",
    "### Lower Right: Φ_DP (Differential Phase)\n",
    "\n",
    "**What it shows**: Cumulative phase shift as the radar beam passes through precipitation. Useful for quantitative precipitation estimation.\n",
    "\n",
    "**Key features to notice**:\n",
    "- **Accumulation with height**: Phase accumulates as the beam passes through more precipitation\n",
    "- **Temporal variations**: Higher values during intense precipitation periods\n",
    "- **Utility for QPE**: Unlike reflectivity, differential phase is relatively unaffected by radar calibration errors and attenuation—making it excellent for rainfall estimation\n",
    "\n",
    "### The Big Picture\n",
    "\n",
    "This storm shows classic stratiform precipitation structure:\n",
    "1. **Ice formation aloft** (5-8 km): Dendritic growth zone, aggregation\n",
    "2. **Melting layer** (3-4 km): Bright band in Z, dip in ρ_HV\n",
    "3. **Rain below** (0-3 km): Moderate reflectivity, low Z_DR\n",
    "\n",
    "The temporal evolution reveals how the storm maintains this structure for ~4 hours—a signature of organized mesoscale convective systems.\n",
    "\n",
    "```{note}\n",
    "**For researchers**: These signatures are used for hydrometeor classification algorithms, microphysics validation in numerical models, and quantitative precipitation estimation. The ability to compute QVPs in seconds (rather than minutes) enables rapid exploration of storm evolution and parameter sensitivity studies.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Performance Comparison\n",
    "\n",
    "Let's quantify the speedup we achieved with the ARCO approach.\n",
    "\n",
    "### Results Summary\n",
    "\n",
    "| Metric | Traditional | ARCO Streaming | Improvement |\n",
    "|--------|-------------|----------------|-------------|\n",
    "| **Total Time** | ~380s (6.3 min) | ~10s | **36x faster** |\n",
    "| **Network Transfer** | ~3.8 GB | ~146 MB | **26x less** |\n",
    "| **Peak RAM** | ~3.3 GB | ~150 MB | **22x less** |\n",
    "| **Sweeps Loaded** | All 17 per file | Only 1 (sweep_16) | Selective |\n",
    "| **Variables Loaded** | All ~8 per sweep | Only 4 selected | Selective |\n",
    "\n",
    "### Why ARCO is Faster\n",
    "\n",
    "1. **Selective Access**: ARCO streams only 4 variables from 1 sweep. Traditional workflow downloads all 17 sweeps and ~8 variables per file—then discards most of it.\n",
    "\n",
    "2. **No Decode Overhead**: ARCO data is already in Zarr format (optimized for cloud access). Traditional files must be decompressed and decoded from binary format.\n",
    "\n",
    "3. **Native Time Indexing**: ARCO supports direct time slicing with `.sel(vcp_time=...)`. Traditional workflow requires parsing filenames and iterating through files.\n",
    "\n",
    "4. **Chunk-Optimized Storage**: Data is stored in chunks aligned with typical access patterns (time, azimuth, range), minimizing unnecessary reads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparison-viz",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-05T17:10:32.799503Z",
     "iopub.status.busy": "2026-02-05T17:10:32.799310Z",
     "iopub.status.idle": "2026-02-05T17:10:33.154363Z",
     "shell.execute_reply": "2026-02-05T17:10:33.153739Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visual comparison\n",
    "traditional_time = 380  # seconds (from benchmark)\n",
    "arco_time = 10  # seconds (approximate from above)\n",
    "\n",
    "traditional_mb = 3809  # MB downloaded\n",
    "arco_mb = 146  # MB streamed\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "categories = [\"Traditional\\n(download files)\", \"ARCO\\n(stream chunks)\"]\n",
    "colors = [\"#0072B2\", \"#009E73\"]\n",
    "\n",
    "# Time comparison\n",
    "bars1 = ax1.bar(\n",
    "    categories,\n",
    "    [traditional_time, arco_time],\n",
    "    color=colors,\n",
    "    edgecolor=\"black\",\n",
    "    linewidth=1.2,\n",
    ")\n",
    "ax1.set_ylabel(\"Total Time (seconds)\", fontsize=11)\n",
    "ax1.set_title(\"Processing Time\", fontsize=12, fontweight=\"bold\")\n",
    "ax1.set_ylim(0, 450)\n",
    "for bar, val in zip(bars1, [traditional_time, arco_time], strict=False):\n",
    "    ax1.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        bar.get_height() + 5,\n",
    "        f\"{val}s\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=11,\n",
    "    )\n",
    "\n",
    "# Data transfer comparison\n",
    "bars2 = ax2.bar(\n",
    "    categories,\n",
    "    [traditional_mb, arco_mb],\n",
    "    color=colors,\n",
    "    edgecolor=\"black\",\n",
    "    linewidth=1.2,\n",
    ")\n",
    "ax2.set_ylabel(\"Data Transfer (MB)\", fontsize=11)\n",
    "ax2.set_title(\"Network Transfer\", fontsize=12, fontweight=\"bold\")\n",
    "for bar, val in zip(bars2, [traditional_mb, arco_mb], strict=False):\n",
    "    ax2.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        bar.get_height() + 10,\n",
    "        f\"{val} MB\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=11,\n",
    "    )\n",
    "ax2.set_ylim(0, 5000)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"workflow_comparison.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nSpeedup: {traditional_time / arco_time:.0f}x faster\")\n",
    "print(f\"Data reduction: {traditional_mb / arco_mb:.1f}x less network transfer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scaling-discussion",
   "metadata": {},
   "source": [
    "### The Real Advantage: Cloud-Native Architecture\n",
    "\n",
    "The speedup you saw isn't just about being \"faster\"—it's about a **fundamentally different architecture** that unlocks new possibilities.\n",
    "\n",
    "#### Why ARCO Scales Differently\n",
    "\n",
    "| Traditional (download-decode-process) | ARCO (stream-on-demand) |\n",
    "|---------------------------------------|-------------------------|\n",
    "| Download entire files to disk | Stream only needed chunks |\n",
    "| Decode all 17 sweeps, all variables | Access single sweep, selected variables |\n",
    "| Linear with file count | Sub-linear with elastic compute |\n",
    "| Limited by local disk I/O | Network-parallel from cloud |\n",
    "\n",
    "#### Key Benefits Beyond Speed\n",
    "\n",
    "1. **Elastic Computing**: Spin up 100 workers and process a year of data in parallel—impossible with file-based workflows\n",
    "\n",
    "2. **Network Optimization**: Only transfer the exact bytes you need. The 5.5x data reduction compounds at scale.\n",
    "\n",
    "3. **No Storage Overhead**: No need to download/store files locally. Stream directly from cloud to memory.\n",
    "\n",
    "4. **Reproducibility**: Icechunk snapshots ensure exact data versioning—critical for scientific workflows.\n",
    "\n",
    "```{important}\n",
    "**The paradigm shift**: Traditional workflows are *file-centric* (process one file at a time). ARCO is *analysis-centric* (define your query, let the system optimize data access). This enables workflows that would be **impractical** with traditional approaches—like computing 30-year climatologies or training ML models on continental-scale radar archives.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reproducibility-connection",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Reproducibility: Science You Can Trust\n",
    "\n",
    "Beyond speed, the Radar DataTree framework enhances scientific reproducibility through **Icechunk's version control**.\n",
    "\n",
    "### Exact Reproduction with Snapshot IDs\n",
    "\n",
    "Every commit to an Icechunk repository generates a unique snapshot ID. Anyone with this ID can access the exact data state you used—even if the repository has been updated since.\n",
    "\n",
    "```python\n",
    "# Example: Open a specific snapshot\n",
    "snapshot_id = \"abc123...\"  # Snapshot ID from your analysis\n",
    "session = repo.readonly_session(snapshot_id)\n",
    "dtree = xr.open_datatree(session.store, ...)\n",
    "```\n",
    "\n",
    "This enables:\n",
    "- **Exact figure reproduction**: Future researchers can reproduce your exact results\n",
    "- **Data provenance**: Track which data versions were used in publications\n",
    "- **Time-travel**: Compare current data to previous versions\n",
    "- **Collaborative research**: Share specific data states with collaborators\n",
    "\n",
    "### FAIR Principles in Action\n",
    "\n",
    "The Radar DataTree framework embodies FAIR data principles:\n",
    "\n",
    "- **Findable**: Cloud storage with metadata-rich DataTree structure\n",
    "- **Accessible**: HTTP access via standard protocols (S3 API, Zarr format)\n",
    "- **Interoperable**: NetCDF/CF conventions, xarray integration\n",
    "- **Reusable**: Version control, clear licensing, comprehensive documentation\n",
    "\n",
    "```{tip}\n",
    "**For publishers**: Include snapshot IDs in your paper's data availability statement. This ensures anyone can reproduce your exact analysis—strengthening peer review and enabling follow-up research.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "takeaways",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "### When to Use Each Approach\n",
    "\n",
    "| Use Case | Recommended |\n",
    "|----------|-------------|\n",
    "| Exploring a single local file | Traditional |\n",
    "| Time-series analysis | **ARCO** |\n",
    "| Multi-month processing | **ARCO** |\n",
    "| Reproducible research | **ARCO** (Icechunk versioning) |\n",
    "| Machine learning training | **ARCO** (high-throughput) |\n",
    "| Real-time monitoring | **ARCO** (selective access) |\n",
    "| Multi-year climatologies | **ARCO** (scalability) |\n",
    "\n",
    "### What You Learned\n",
    "\n",
    "In this notebook, you:\n",
    "- Reproduced a published scientific figure in ~10 seconds (36x faster than traditional)\n",
    "- Learned how QVPs reveal precipitation microphysics through polarimetric signatures\n",
    "- Interpreted melting layers, aggregation zones, and storm structure from time-height displays\n",
    "- Explored the ARCO workflow: connect → navigate → select → stream\n",
    "- Understood how selective access and cloud-optimized formats enable dramatic speedups\n",
    "- Discovered how Icechunk versioning enables exact reproducibility\n",
    "\n",
    "### Challenge Yourself\n",
    "\n",
    "```{admonition} Try These Extensions\n",
    ":class: tip\n",
    "\n",
    "1. **Compare different storms**: Analyze QVPs from other MC3E cases. How do polarimetric signatures differ between convective vs. stratiform precipitation?\n",
    "\n",
    "2. **Multi-elevation QVPs**: Compute QVPs at multiple elevation angles (e.g., sweep_8, sweep_12, sweep_16). How does beam height affect the observed signatures?\n",
    "\n",
    "3. **Quantitative analysis**: Extract the melting layer height from the ρ_HV minimum. How does it change over time? Does it correlate with surface temperature?\n",
    "\n",
    "4. **Compare radars**: Process the same time period from a nearby radar (e.g., KTLX). Do you see consistent features?\n",
    "\n",
    "5. **Long-term climatology**: Compute monthly-averaged QVPs for an entire year. What seasonal patterns emerge in precipitation structure?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "references",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "**Primary Reference**:\n",
    "* Ryzhkov, A., et al., 2016: Quasi-Vertical Profiles—A New Way to Look at Polarimetric Radar Data. *J. Atmos. Oceanic Technol.*, **33**, 551–562, https://doi.org/10.1175/JTECH-D-15-0020.1.\n",
    "\n",
    "**Cloud-Native Data**:\n",
    "* Abernathey, R.P., et al., 2021: Cloud-Native Repositories for Big Scientific Data. *Comput. Sci. Eng.*, **23**, 26–35, https://doi.org/10.1109/MCSE.2021.3059437.\n",
    "\n",
    "**Radar DataTree Framework**:\n",
    "* Ladino-Rincón, A., & Nesbitt, S. W., 2025: Radar DataTree: A FAIR and Cloud-Native Framework for Scalable Weather Radar Archives. *arXiv preprint*, arXiv:2510.24943."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
